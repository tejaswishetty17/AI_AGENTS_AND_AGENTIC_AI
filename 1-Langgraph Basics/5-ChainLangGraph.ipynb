{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972d486a",
   "metadata": {},
   "source": [
    "### Chain Using LangGraph\n",
    "In this section we will see how we can build a simple chain using Langgraph that uses 4 important concepts\n",
    "\n",
    "- How to use chat messages as our graph state\n",
    "- How to use chat models in graph nodes\n",
    "- How to bind tools to our LLM in chat models\n",
    "- How to execute the tools call in our graph nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19a6a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f4437",
   "metadata": {},
   "source": [
    "#### How to use chat messages as our graph state\n",
    "##### Messages\n",
    "\n",
    "We can use messages which can be used to capture different roles within a conversation.\n",
    "LangChain has various message types including HumanMessage, AIMessage, SystemMessage and ToolMessage.\n",
    "These represent a message from the user, from chat model, for the chat model to instruct behavior, and from a tool call.\n",
    "\n",
    "Every message have these important components.\n",
    "\n",
    "- content - content of the message\n",
    "- name - Specify the name of author\n",
    "- response_metadata - optionally, a dict of metadata (e.g., often populated by model provider for AIMessages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e842fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Please tell me how can I help you!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Tejas\n",
      "\n",
      "I want to learn coding\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLMModel\n",
      "\n",
      "Which programming language you want to learn\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Tejas\n",
      "\n",
      "I want to learn Python Programming Language\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "messages = [AIMessage(content = f\"Please tell me how can I help you!\", name=\"LLMModel\")]\n",
    "messages.append(HumanMessage(content=f\"I want to learn coding\", name=\"Tejas\"))\n",
    "messages.append(AIMessage(content=f\"Which programming language you want to learn\", name=\"LLMModel\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn Python Programming Language\", name=\"Tejas\"))\n",
    "\n",
    "for message in messages:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b94a7b",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "We can use the sequence of message as input with the chatmodels using LLM's and OPENAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d601a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Python is a versatile and beginner-friendly programming language. Hereâ€™s a step-by-step guide to help you get started:\n",
      "\n",
      "### 1. **Set Up Your Environment**\n",
      "   - **Install Python**: Download and install Python from the [official website](https://www.python.org/downloads/). Make sure to check the box that says \"Add Python to PATH\" during installation.\n",
      "   - **Choose an IDE/Text Editor**: You can use any text editor, but popular choices include:\n",
      "     - **VS Code**: A powerful code editor with many extensions.\n",
      "     - **PyCharm**: A dedicated Python IDE.\n",
      "     - **Jupyter Notebook**: Great for data science and interactive coding.\n",
      "\n",
      "### 2. **Learn the Basics**\n",
      "   - **Syntax and Data Types**: Understand variables, strings, integers, floats, lists, tuples, and dictionaries.\n",
      "   - **Control Structures**: Learn about `if` statements, loops (`for`, `while`), and how to control the flow of your program.\n",
      "   - **Functions**: Learn how to define and call functions, and understand the concept of scope.\n",
      "\n",
      "### 3. **Practice Coding**\n",
      "   - **Online Platforms**: Use platforms like [LeetCode](https://leetcode.com/), [HackerRank](https://www.hackerrank.com/), or [Codecademy](https://www.codecademy.com/) to practice coding problems.\n",
      "   - **Projects**: Start small projects like a calculator, a to-do list app, or a simple game.\n",
      "\n",
      "### 4. **Explore Libraries and Frameworks**\n",
      "   - **Data Science**: Learn libraries like NumPy, Pandas, and Matplotlib.\n",
      "   - **Web Development**: Explore Flask or Django for building web applications.\n",
      "   - **Automation**: Use libraries like `requests` for web scraping or `selenium` for browser automation.\n",
      "\n",
      "### 5. **Join a Community**\n",
      "   - Engage with communities on platforms like [Stack Overflow](https://stackoverflow.com/), [Reddit](https://www.reddit.com/r/learnpython/), or [Discord](https://discord.com/) servers focused on Python.\n",
      "\n",
      "### 6. **Keep Learning**\n",
      "   - Follow tutorials, read books, and watch videos. Some recommended resources include:\n",
      "     - **Books**: \"Automate the Boring Stuff with Python\" by Al Sweigart, \"Python Crash Course\" by Eric Matthes.\n",
      "     - **Online Courses**: Check out courses on platforms like Coursera, Udemy, or edX.\n",
      "\n",
      "### 7. **Build a Portfolio**\n",
      "   - As you gain more experience, start building a portfolio of your projects on GitHub. This will be helpful if you decide to pursue a career in programming.\n",
      "\n",
      "### 8. **Stay Updated**\n",
      "   - Follow Python-related blogs, podcasts, and YouTube channels to stay updated with the latest trends and best practices.\n",
      "\n",
      "Feel free to ask if you have any specific questions or need further guidance! Happy coding!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature=0)\n",
    "response = llm.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "666eab2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 618,\n",
       "  'prompt_tokens': 61,\n",
       "  'total_tokens': 679,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-4o-mini-2024-07-18',\n",
       " 'system_fingerprint': 'fp_8bda4d3a2c',\n",
       " 'id': 'chatcmpl-CD4Abvtfa2uu8RInvCnrgyz44wUBN',\n",
       " 'service_tier': 'default',\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff4dd7",
   "metadata": {},
   "source": [
    "### Tools\n",
    "Tools can be integrated with the LLM models to interact with external systems. External systems can be API's, third party tools.\n",
    "\n",
    "Whenever a query is asked the model can choose to call the tool and this query is based on the \n",
    "natural language input and this will return an output that matches the tool's schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb3f5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int,b:int)-> int:\n",
    "    \"\"\" Add a and b\n",
    "    Args:\n",
    "        a (int): first int\n",
    "        b (int): second int\n",
    "\n",
    "    Returns:\n",
    "        int\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c73c2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000019AA4E7F4D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019AA492C2C0>, root_client=<openai.OpenAI object at 0x0000019AA3535E80>, root_async_client=<openai.AsyncOpenAI object at 0x0000019AA4E7C590>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecfab507",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binding tool with llm\n",
    "\n",
    "llm_with_tools=llm.bind_tools([add])\n",
    "\n",
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 2\",name=\"Krish\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae99760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 2},\n",
       "  'id': 'call_1JSXS6xslcmp68k1jShra7BR',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
